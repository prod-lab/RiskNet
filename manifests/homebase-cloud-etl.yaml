apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: pyspark-k8s-boilerplate-cloud-etl
  namespace: spark-operator
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "gcr.io/${PROJECT}/pyspark-k8s-boilerplate:latest"
  imagePullPolicy: Always
  mainApplicationFile: local:///opt/spark/work-dir/src/pyspark_k8s_boilerplate/main.py
  arguments:
    - --job
    - pyspark_k8s_boilerplate.jobs.cloud_etl
  sparkVersion: "3.1.2"
  restartPolicy:
    type: Never
  volumes:
    - name: "shared-volume"
      hostPath:
        path: "/shared"
        type: Directory
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.1.2
    serviceAccount: my-release-spark
    volumeMounts:
      - name: "shared-volume"
        mountPath: "/shared"
    secrets:
      - name: key-file
        path: /secrets
        secretType: generic
  executor:
    cores: 1
    instances: 1
    memory: "1024m"
    labels:
      version: 3.1.2
    volumeMounts:
      - name: "shared-volume"
        mountPath: "/shared"
    secrets:
      - name: key-file
        path: /secrets
        secretType: generic